{% extends 'base.html' %}

{% block content %}
    <section class="project-1">
        <div class="container">
            <h2>INSTANCE SEGMENTATION USING MASK R-CNN ON CUSTOM DATASET USING PYTHON</h2>
            <p>I utilized the Detectron2 Mask R-CNN baseline package, which includes a pre-trained algorithm, and 
                conducted transfer learning on a custom dataset consisting of 57 goat images. To ensure model effectiveness, 
                I initially divided the goat images into training and validation datasets and subsequently annotated them 
                individually using the VIA annotation tool. Subsequently, I developed a user-friendly web interface in Python 
                using the Flask framework, hosted on Google Colab with NGROK for easy accessibility. While I focused primarily on 
                the functionality of the web application and the model, I admit that I didn't invest extensively in the visual design 
                aspects. The primary objective of this project was to demonstrate the capabilities of the web application and validate 
                the functionality of my custom model. The link to this project can be found using this link <a href="https://drive.google.com/file/d/1KSjVH5tKb9t7QCFSGFJT8r15g_kYaUjb/view?usp=sharing">Instance Segmentation Colab Notebook</a>.
                This link will give you access to the Flask web application using an NGROK token <a href="https://drive.google.com/file/d/1zfBCSKQE7TqJ48g_tvi1AO4-ZtPfzRXU/view?usp=drive_link">Flask Web Application Code</a>.
            </p>
            
        </div>
    </section>

    <section class="project-2">
        <div class="container">
            <h2>BEHAVIORAL RISK FACTOR SURVEILLANCE SYSTEM DATA ANALYSIS USING R AND RSTUDIO</h2>
            <p>In this project, my analysis spanned various crucial tasks, including data exploration, 
                linear regression modeling, hypothesis testing, model comparison, data visualization, and the 
                implementation of logistic regression. I conducted these analytical procedures using the R 
                programming language in conjunction with RStudio. This project can be found on my Github account 
                using this link <a href="https://github.com/christopherbrunswick/BRFSS2015-Data-Analysis">BRFSS Data Analysis</a>.
            </p>
        </div>
    </section>

    
    <section class="project-3">
        <div class="container">
            
            <h2>STATISTICAL ANALYSIS OF PROTEIN EXPRESSION FROM LAB SUBJECT BRAIN USING R AND RSTUDIO</h2>
            <p>In this project, I conducted a comprehensive analysis involving several key steps. Initially, 
                I computed the mean protein expression values for two distinct groups: mice with injured brains 
                and normal control mice. Subsequently, I calculated the standard deviation of protein expression 
                within each of these groups for every protein under consideration. Following these initial computations, 
                I performed a series of two-sample t-tests to compare the mean protein expression levels between the 
                mice with injured brains and the normal control mice for each protein. The outcomes of these t-tests 
                were then used to sort the proteins in ascending order based on their associated p-values. 
                I identified proteins with statistically significant mean expression differences between the 
                mice with injured brains and the normal control mice, considering p-values below both 0.05 and 0.01 
                thresholds. Lastly, I extracted the t values from the t-tests and utilized them to create a graphical 
                representation of the relationship between p-values and t values, aiding in the visualization of the 
                statistical significance and effect size for each protein. This project can be found on my Github account 
                using this link <a href="https://github.com/christopherbrunswick/R-hands-on-work-and-project/blob/master/R/RprojectNoOutP12.Rmd">Mice Brain Data Analysis</a>
            </p>
        </div>
    </section>

    
    <section class="project-4">
        <div class="container">
            <h2>STATISTICAL ANALYSIS ON BLUE CROSS BLUE SHIELD DIABETES DATASET USING SAS</h2>
            <p>In this project, I executed a sequence of tasks utilizing the SAS statistical programming language.
                This project can be found on my github account using this link <a href="https://github.com/christopherbrunswick/SAS-hands-on-work-and-final-project/blob/master/SAS_programming/Final%20Project%20SAS/FinalProjectSAS.sas">Statistical Analsis on a Diabetes Dataset Using SAS</a>
            </p>
        </div>
    </section>

    
    <section class="project-5">
        <div class="container">
            <h2>DATA PREPARATION AND EXPLORATORY DATA ANALYSIS ON KAGGLE'S SPOTIFY DATASET</h2>
            <p>Data collection, data preparation, and data exploration/analysis represent the foundational pillars 
                of any data science project. The accuracy and precision of these components are pivotal, as they 
                underpin the success of the subsequent machine learning phases. When these components are flawed, 
                it can result in one of two critical scenarios: high bias - low variance or low bias - high variance.
                High bias - low variance scenarios tend to produce under-fitted models, while low bias - high variance can 
                lead to over-fitted models. The ultimate objective is to achieve a balanced bias-variance tradeoff in the 
                final model. In this project, I embarked on an exploration of Python packages suitable for performing comprehensive 
                exploratory data analysis. To facilitate this, I established a dedicated virtual environment named "EDA2" to 
                install and manage the requisite packages. Within this project framework, I executed various tasks, including the 
                identification of categorical variables, the removal of text data from dataframes for potential future use, systematic 
                examination of missing data points, assessment of random variable distributions, visualization of temporal variations in data 
                points for a selected variable over the years, identification of duplicate indices, identification of outliers in random variables, 
                and the normalization of a chosen skewed random variable. As part of this process, I systematically applied a range of transformations 
                to identify the approach that would yield the most symmetrical distribution, ideally conforming to a Gaussian or normal distribution. 
                It's important to note that, in alignment with the project's goals, I deliberately refrained from using scikit-learn, as the primary 
                objective was not to construct predictive models but rather to focus on data exploration and analysis.
                This project can be found on my github account using this link <a href="https://github.com/christopherbrunswick/exploratory-data-analysis/blob/master/Exploratory_Data_Analysis_Project.py">Exploratory Data Analysis Using Python and Jupyter Notebook</a></p>
        </div>
    </section>

    
    <section class="project-6">
        <div class="container">
            <h2>PERFORMING REGRESSION TASKS ON BIKE RENTAL DATASET (TEXTBOOK PROJECT)</h2>
            <p> This project was an exploration of novel data acquisition and modeling techniques, distinct from previous endeavors. 
                Leveraging web scraping techniques using Beautiful Soup, I gathered the dataset from a web directory. I extended the 
                project by incorporating various algorithms such as kNN Regression, Random Forests, and XGBoost, coupled with methodologies 
                like GridSearchCV, RandomizedSearchCV, and BayesSearchCV, along with hyperparameter tuning.
                The resulting best model showcased a 76% increase in accuracy over the initial textbook's simple linear regression model. 
                Almost 100% of the target data points aligned with the regression line, signifying a high level of explanation for the target 
                variable's variation. In comparison to the textbook's GradientBoostingRegressor(), the model displayed an 11% enhancement in predictive 
                accuracy. However, despite its accuracy and robustness, this sophisticated model doesn't seamlessly translate into a user-friendly web 
                app with an intuitive interface. While it excels in predicting bike counts based on historical data, it lacks simplicity for user interaction. 
                The most user-friendly model remains the linear regression model, allowing users to input coefficient values and receive a single bike count prediction
                 based on their inputs. The textbook creators have already developed a web app for predicting bike rental counts.
                Ultimately, the primary objective of this project, as per the creators, was simply to predict bike rental counts.
                The jupyter notebook for this project can be found on my github account using this link <a href="https://github.com/christopherbrunswick/bike_rental_demand_prediction_web_app/blob/master/Regression_on_Bike_Sharing_jupnb.py">Regression Tasks on a Bike Rental Dataset</a>
            </p>
        </div>
    </section>

    
    <section class="project-7">
        <div class="container">
            <h2>SPLIT-TESTING (A/B TESTING) ON A KAGGLE DATASET</h2>
            <p>This project originated from an initiative to conduct a split test, specifically an A/B test, using a 
                Kaggle dataset. The inspiration for this endeavor was drawn from Renato Fillinich's insightful Medium 
                article titled <i>A/B testing: A step-by-step guide in Python</i>. The primary objective is to assess 
                whether the updated version of a website outperforms its older counterpart. Given the uncertainty 
                regarding the comparative performance of the two versions, a two-tailed hypothesis test is employed 
                to ascertain statistical significance. The comprehensive Jupyter notebook for this project is accessible 
                on my GitHub repository via the following link <a href="https://github.com/christopherbrunswick/split-testing/blob/master/project-1/AB_Testing_1.py">Split-test (A/B test) #1</a>
            </p>
        </div>
    </section>

   
    <section class="project-8">
        <div class="container">
            <h2>TIME SERIES ANALYSIS (MACHINE LEARNING) ON MONTHLY TEMPERATURES 1880-2016 IN PYTHON (Current)</h2>
            <p>The completion of this project has been postponed to a later undefined date.</p>
        </div>
    </section>

    
    <section class="project-9">
        <div class="container">
            <h2>WEB-BASED MASTER DATA MANAGEMENT SOLUTION</h2>
            <p>This is a prototypical version of a master data management solution. The frontend uses a bubble.io as a node-code low-code solution so,
                the frontend of this data management solution has a limited amount of scalability and in no way is considered a feasible solution to have in production.
                This solution uses Auth0 as an identity provider. User are authenticated with OIDC authentication protocol can either be redirected as an administrative user
                or standard user. ExpressJS is used to build the resource server and an api for Flask server calls on a function that performs the mathematical computation for
                the entity resolution process to create the linkage between existing records in SQL server database and a user uploaded .csv file. This is a large-scale solution
                that is currently being worked on.
                <!-- a href="github link to project"  Master Data Management Solution Prototype -->
            </p>
        </div>
    </section>

    <section class="project-10">
        <div class="container">
            <h2>EXAMPLE APPS2GO LANDING PAGE CONCEPT</h2>
            <p>Simple landing page with a cool UI design. The click effect was borrowed from
                <!-- a href="" Landing Page Concept -->
            </p>
        </div>
    </section> 

     <section class="project-11">
        <div class="container">
            <h2>EXAMPLE ANALYTICS CONSULTANCY WEB APPLICATION</h2>
            <P>Simple web application that accepts contact information from an end user. This project uses
                the WAMP stack and boostrap for styling. I packaged this app with Docker for portability and scalability
                in the future. <a href="https://github.com/christopherbrunswick/example_consultancy_web_application.git">Analytics Consultancy Web App (WAMP)</a>
            </P>
        </div>
     </section>

      <section class="project-12">
        <div class="container">
            <h2>DATAPILOT</h2>
            <p>DataPilot is a full-stack app being built for performance, scalability, and maintainability. The tech stack for this application 
                includes solid, tailwind, sql server, and express. The target build for this app is a prototype for a much larger solution. Further
                details on this project will be undisclosed.
            </p>
        </div>
      </section>
{% endblock %}